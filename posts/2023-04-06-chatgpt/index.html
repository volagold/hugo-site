<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>ChatGPT has taken the world by storm. What's Next? | lifei.ai | AI blogs</title><meta name=keywords content="gpt,chatgpt,nlp"><meta name=description content="On April 11, 2022, I wrote the following:
&ldquo;While current models may still have limited capacity, I&rsquo;m optimistic that, we should see better and better AI models coming out in the future, and one day machines can have enough intelligence to handle tasks and jobs we do today.&rdquo;
7 months later, OpenAI released ChatGPT, the performance of which has stunned the public. It can chat, write stories, debug code&mldr;there hasn&rsquo;t been a chatbot that is so intelligent and so fluent in dialogues with human."><meta name=author content="Fei Li"><link rel=canonical href=https://lifei.ai/posts/2023-04-06-chatgpt/><link crossorigin=anonymous href=/assets/css/stylesheet.415e3a8d51db2ff1dd1daeb6ed47da1d29ea7215172df9a95da9a546c6c5ba84.css integrity="sha256-QV46jVHbL/HdHa627UfaHSnqchUXLfmpXamlRsbFuoQ=" rel="preload stylesheet" as=style><link rel=icon href=https://lifei.ai/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://lifei.ai/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://lifei.ai/favicon-32x32.png><link rel=apple-touch-icon href=https://lifei.ai/apple-touch-icon.png><link rel=mask-icon href=https://lifei.ai/apple-touch-icon.png><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><link rel=stylesheet type=text/css href=/hugo-cite.css><script src=https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.4/katex.min.js integrity="sha512-sHSNLECRJSK+BFs7E8DiFc6pf6n90bLI85Emiw1jhreduZhK3VXgq9l4kAt9eTIHYAcuQBKHL01QKs4/3Xgl8g==" crossorigin=anonymous referrerpolicy=no-referrer></script>
<link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.4/katex.min.css integrity="sha512-mQwom8Ns4op+H29oDkD/LXO/OsXPvCFfkgZkFAVrhhePzRLU8NUI3Nkm43NhWUSmj3p5Cca2HTEkMQmXQRwDQQ==" crossorigin=anonymous referrerpolicy=no-referrer><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.21/dist/contrib/mhchem.min.js integrity=sha384-F2ptQFZqNJuqfGGl28mIXyQ5kXH48spn7rcoS0Y9psqIKAcZPLd1NzwFlm/bl1mH crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.4/contrib/auto-render.min.js integrity="sha512-iWiuBS5nt6r60fCz26Nd0Zqe0nbk1ZTIQbl3Kv7kYsX+yKMUFHzjaH2+AnM6vp2Xs+gNmaBAVWJjSmuPw76Efg==" crossorigin=anonymous referrerpolicy=no-referrer onload=renderMathInElement(document.body)></script>
<script>document.addEventListener("DOMContentLoaded",function(){renderMathInElement(document.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1}]})})</script><script async src="https://www.googletagmanager.com/gtag/js?id=G-QV43D2GXK2"></script>
<script>var doNotTrack=!1;if(!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-QV43D2GXK2",{anonymize_ip:!1})}</script><meta property="og:title" content="ChatGPT has taken the world by storm. What's Next?"><meta property="og:description" content="On April 11, 2022, I wrote the following:
&ldquo;While current models may still have limited capacity, I&rsquo;m optimistic that, we should see better and better AI models coming out in the future, and one day machines can have enough intelligence to handle tasks and jobs we do today.&rdquo;
7 months later, OpenAI released ChatGPT, the performance of which has stunned the public. It can chat, write stories, debug code&mldr;there hasn&rsquo;t been a chatbot that is so intelligent and so fluent in dialogues with human."><meta property="og:type" content="article"><meta property="og:url" content="https://lifei.ai/posts/2023-04-06-chatgpt/"><meta property="og:image" content="https://lifei.ai/imgs/chatgpt/cover.jpeg"><meta property="article:section" content="posts"><meta property="article:published_time" content="2023-04-06T00:00:00+00:00"><meta property="article:modified_time" content="2023-04-06T00:00:00+00:00"><meta property="og:site_name" content="lifei.ai | AI blogs"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://lifei.ai/imgs/chatgpt/cover.jpeg"><meta name=twitter:title content="ChatGPT has taken the world by storm. What's Next?"><meta name=twitter:description content="On April 11, 2022, I wrote the following:
&ldquo;While current models may still have limited capacity, I&rsquo;m optimistic that, we should see better and better AI models coming out in the future, and one day machines can have enough intelligence to handle tasks and jobs we do today.&rdquo;
7 months later, OpenAI released ChatGPT, the performance of which has stunned the public. It can chat, write stories, debug code&mldr;there hasn&rsquo;t been a chatbot that is so intelligent and so fluent in dialogues with human."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://lifei.ai/posts/"},{"@type":"ListItem","position":2,"name":"ChatGPT has taken the world by storm. What's Next?","item":"https://lifei.ai/posts/2023-04-06-chatgpt/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"ChatGPT has taken the world by storm. What's Next?","name":"ChatGPT has taken the world by storm. What\u0027s Next?","description":"On April 11, 2022, I wrote the following:\n\u0026ldquo;While current models may still have limited capacity, I\u0026rsquo;m optimistic that, we should see better and better AI models coming out in the future, and one day machines can have enough intelligence to handle tasks and jobs we do today.\u0026rdquo;\n7 months later, OpenAI released ChatGPT, the performance of which has stunned the public. It can chat, write stories, debug code\u0026hellip;there hasn\u0026rsquo;t been a chatbot that is so intelligent and so fluent in dialogues with human.","keywords":["gpt","chatgpt","nlp"],"articleBody":"On April 11, 2022, I wrote the following:\n“While current models may still have limited capacity, I’m optimistic that, we should see better and better AI models coming out in the future, and one day machines can have enough intelligence to handle tasks and jobs we do today.”\n7 months later, OpenAI released ChatGPT, the performance of which has stunned the public. It can chat, write stories, debug code…there hasn’t been a chatbot that is so intelligent and so fluent in dialogues with human. Previously, AI applications are largely passive: think about face recognition, speech recognition, OCR, autonomous driving, recommendation systems…they are deployed largely in the backstage and are not something that people directly interact with. ChatGPT is different: it is like a person that everyone can talk to at any time. Its interactive nature quickly lets it become popular around the world.\nAs we will see, there is not much magic behind ChatGPT. Its building block is Attentions [1] and Transformers [2], which were proposed in 2014 and 2017 respectively, so ChatGPT didn’t employ any radically new technologies. Here is a high-level summary of their approach: First, a large neural network model is trained on Internet data to predict the next word. Then it is fine-tuned on prompt-response dialogue dataset created by human labelers. Its generated responses to prompts are then evaluated by humans, and the model is further trained to maximize human evaluation score. That’s basically it. However, idea is one thing, and how to scale an idea to make it work in real world is another. What is truly marvelous about OpenAI is their exceptional engineering efforts, from data collection to training, monitoring, and deployments. Never underestimate the investments required to make something like ChatGPT!\nThe Models Model Date Size GPT June 2018 117M GPT-2 February 2019 1.5B GPT-3 May 2020 175B ChatGPT Nov 2022 undisclosed GPT-4 March 2023 undisclosed GPT GPT [3] is not very complicated. It is a transformer model. All it does is to output a probability distribution over the next word given the input context. To generate next word, one selects the word with the highest probability. Here is a snapshot from the paper:\nGPT model\nGiven previous context $[u_{i-k}…u_{i-1}]$, the simplest way to generate the next word $u_i$ is to assume that it only depends on its left neighbor $u_{i-1}$, count the occurrence of all words that come after $u_{i-1}$ in the training corpus, and then select the word with the highest frequency. This is the 2-gram model we talked about earlier.\nTo model context dependence, we need something more sophisticated than that. The Attention model [1] is the exact opposite of the Markov assumption of context independence. It is a simple and efficient way to pay attention to previous context when generating the next word. An output $u_i$ is a weighted sum of all the words in its context $(u_{i-1},\\ldots,u_{i-k})$:\n$$ u_i = \\alpha_1 v_{i-1} + \\alpha_2 v_{i-2} + \\cdots + \\alpha_k v_{i-k}, $$\nwhere the weight $\\alpha_i$ represents how much the output should pay attention to $u_i$, and $v_k=Vu_{i-k}$ with learnable parameter matrix $V$. See this post for detail. This way,\nthe computation is easily parallelizable, so is very suitable for GPU computation; can easily scale to long contexts, for example 3000 tokens or even more; can easily scale up model size. Not all model architectures in deep learning are easily scalable. Scalability is clearly one of the biggest advantages of the Attention model.\nThe Transformer model [2] is attention layer plus residual layer, linear layer and normalization.\nTransformer model architecture\nThose extra components are also indispensable:\nResidual connections ensure that gradients can directly flow backward from output to input. Without it convergence is often difficult. Normalization addresses over-fitting and ensures robust learning. Without it training loss can easily explode. Linear layers add more parameters, increasing model capacities. Without it the loss will be higher, performance will be much worse. And here you are. 12 layers of Transformer blocks. That’s basically GPT.\nIn those days, fine-tuning on downstream tasks is standard practice. To apply GPT in each kind of problem, it has to be fine-tuned on each kind of such dataset. Here is a description from the paper [3]:\nAfter training the model with the objective, we adapt the parameters to the supervised target task…we assume a labeled dataset $\\mathcal{C}$, where each instance consists of a sequence of tokens, $x^1,\\ldots,x^m$, along with a label $y$. The inputs are passed through our pre-trained model to obtain the final transformer block’s activation $h_l^m$, which is then fed into an added linear output layer with parameters $W_y$ to predict $y$:\n$$P(y \\mid x^1,\\ldots,x^m) = \\texttt{softmax}(h_l^mW_y).$$\nThis gives us the following objective to maximize: $$L_2(\\mathcal{C}) = \\sum_{(x,y)}\\log P(y\\mid x^1,\\ldots,x^m).$$\nSince GPT only accepts sequences of fixed length as inputs, training data has to be structured as sequences, with delimiters separating different sections of input. For example, for question answering task, context and choices are delimited before feeding to the model.\nTo fine-tune GPT on downstream tasks, inputs in datasets have to be transformed to sequence-like structures.\nIf a model is trained on large enough data, does it need fine-tuning at all? GPT-2 brought up this idea of “zero-shot”, which was a novel practice at that time.\nGPT-2 The GPT-2 [4] model architecture is the same as GPT: Transformers. Beside the differences below, it is basically a larger version of GPT:\nGPT-2 was trained on a much larger dataset. GPT model was trained on the BooksCorpus [9] dataset. In GPT-2, they scaped the Internet and created a dataset called WebText, which contains 8 million documents for a size of 40 GB. In GPT-2, layer normalization was moved to the beginning, rather than the end of each sub-block. An additional layer normalization was added after the final self-attention block. Context size was increased from 512 to 1024 tokens. These changes played very important roles in improving model performance. But the most significant paradigm shift from GPT to GPT-2 is zero-shot. The authors realized that, with enough training data, the model can learn various tasks directly from the dataset, without any explicit supervision (hence the title “Language Models are Unsupervised Multitask Learners”).\nSupervised learning and unsupervised or generative learning are not a dichotomy. On the one hand, generative learning is disguised supervised learning. Generative training on text sequences can be seen as repeatedly applying supervised learning to predict a label (the next word) given some text input (context). On the other hand, some supervised learning tasks can be formulated as generative learning tasks. For example, as mentioned in [4], for translation, instead of training on (english, french) input and output pairs, a generative model can be trained on (translate to french, english text, french text) sequences. If the model possesses enough context learning ability, and if such tasks appear naturally and abundantly in the training corpus, which is the case, then we can expect the model to possess at least some language translation ability after training. The two are different ways to formulate the same thing: make predictions given inputs.\nAn example in GPT-2 paper showing naturally occurring language translation pairs found in training dataset\nHowever, generative training on vast amount of unlabeled data provides advantages over supervised training on well-prepared labeled data $(x,y)$. The effort to prepare such labeled data is expensive, labor-intensive and time-consuming, and is also hard to scale up. Let’s take a thought experiment. Suppose supervised learning has 80% efficiency of learning from labeled data, while unsupervised learning has only 20% efficiency of learning from unlabeled data. Even though labeled data provide greater learning efficiency than that of unlabeled data, if the amount of unlabeled data greatly surpasses that of labeled data, then eventually an unsupervised learning model will become more powerful than a supervised one trained on far less amount of data. What’s more, a generative model trained on vast and diverse source of texts can pick up multiple abilities from data, while a supervised one can only perform that one specific task defined by the training dataset $\\{(x_i,y_i)\\}_{i=1}^{N}$.\nGPT-2 is the starting point where we later see amazing performance of generative AI. When the model size gets larger, the performance continues to get better. There is no reason to stop training models with larger sizes.\nAs model size gets larger, performance gets better.\nGPT-3 GPT-3 [5] largely shares the same architecture as GPT-2, but is significantly larger, with 175B parameters. For reference, here is a short description from the paper:\nWe use the same model and architecture as GPT-2 …… with the exception that we use alternating dense and locally banded sparse attention patterns in the layers of the transformer, similar to the Sparse Transformer.\nThe most silent aspect of the GPT-3 paper is that an extensive series of experiments were conducted, and the GPT-3 model achieved strong performances across multiple tasks. The experiments strongly suggest that scaling up model size is the way to obtain better performance.\nThere is no end in scaling\nThere is no end in scaling\nThere is no end in scaling\nThere is no end in scaling\nThere is no end in scaling\nThere is no end in scaling\nGPT-3 is able to write stories and news articles. It was pretty impressive at that point, and caught some public attention. But still it was not something that anyone can directly interact with, so many people were still not aware of it.\nInstructGPT GPT-3 is optimized to produce web-like documents. If you give the model an instruction, like “explain …. to me”, it will not know how to respond to this particular instruction, but instead it is likely to produce something that looks like articles that contain similar sentences in the training data. In OpenAI’s term, the model is misaligned.\nInstructGPT [6] addresses this problem by resorting to supervised fine-tuning. Below is an overview of the approach from the paper. Step 1 is to fine-tune on high quality human-crafted instruction-response dataset. Step 2 is to train a reward model, and step 3 is to train the model to maximize reward model output. The last two steps are called Reinforcement Learning with Human Feedback (RLHF), which proves to be an effective way of aligning model to human instructions. It shares similarity with GAN, in which a generative model is trained to optimize output score from a discriminative model. In GAN the two models are trained concurrently. Here in InstructGPT the two models are trained separately.\nInstructGPT. (1) A pre-trained LM is fine-tuned using supervised learning on human-written dataset. (2) Collect human rankings on model outputs and train a discriminative model on this dataset. (3) Train the fine-tuned LM so that its generated responses to prompts maximize the discriminative model’s output.\nHere are the methods in detail:\nFirst, a pre-trained GPT-3 model is fine-tuned on prompt-response dataset created by 40 labelers. The dataset contains about 13k training prompts. The fine-tuned model is called SFT (which stands for “Supervised Fine-Tuning”).\nSecond, given a prompt, sample several outputs (from $K=4$ to $K=9$) from the model. A human labeler then ranks the outputs. Collect such human ranking dataset, and train a reward model (RM) on the dataset. In InstructGPT paper [6], the RM model is a GPT-3 model with 6B parameters. The training objective is the pairwise ranking loss\n$$ \\text{loss}(\\theta) = -\\frac{1}{K \\choose 2} E_{(x, y_w, y_l)\\sim D}[\\log(\\sigma(r_\\theta(x,y_w) - r_\\theta(x, y_l)))] $$\nwhere $r_\\theta(x, y)$ is the scalar output of the reward model for prompt $x$ and completion $y$ with parameters $\\theta$, $y_w$ is the preferred completion out of the pair of $y_w$ and $y_l$, and $D$ is the dataset of human comparisons. The RM dataset has 33k training prompts.\nFinally, fine-tune the SFT model again, such that its output will have a high reward score from the RM model. This is called Proxy Policy Optimization (PPO) in InstructGPT paper [6], which is about optimizing (maximizing) the following objective: $$ \\text{objective}(\\phi) = E_{(x,y)\\sim D_{\\pi_\\phi^{RL}}}[r_\\theta(x,y) - \\beta\\log\\left(\\pi_\\phi^{RL}(y\\mid x) / \\pi^{SFT}(y\\mid x)\\right)] + \\gamma E_{x\\sim D_{\\text{pretrain}}}[\\log(\\pi_\\phi^{RL}(x))]. $$\nHere, $\\pi^{SFT}$ is the fine-tuned model from step 1, which is kept fixed, and $\\pi_{\\phi}^{RL}$ (called “RL policy”) is a copy of $\\pi^{SFT}$ whose parameters are going to be updated by training. $x$ is prompt, and $y$ is the response output from the model.\nThe first term is the main objective we want to maximize. Note that, sampling comes from the model we are training, rather than a fixed dataset. After gradient updates, the sample distribution will be different.\nThe second term (negative KL divergence between distribution $\\pi_\\phi^{RL}(y\\mid x)$ and $\\pi^{SFT}(y\\mid x)$) is a regularization term that penalizes deviation from the fine-tuned model from step 1. This is added to avoid losing all the information stored in the weights of the fine-tuned model.\nThe third term is also a regularization term. It is the objective of language modeling (maximizing log likelihood on next word). This is to prevent the model from focusing too much on increasing $r_\\theta(x,y)$ and forgetting about next-word generation.\nChatGPT ChatGPT was released on November 30, 2022, and soon caused a technology revolution around the world. Numerous applications like copy.ai and typeface.ai quickly emerged. I was impressed by how LLMs can dramatically boost human productivity. The point is not about whether ChatGPT will make not mistake and always give accurate answers. Rather, the point is that, it showed us how AI can have huge potential impacts on society.\nRegarding model details, at this point, OpenAI is no longer open anymore. It didn’t publish research paper on ChatGPT. We can only infer information about the model from its blog:\nMethods\nWe trained this model using Reinforcement Learning from Human Feedback (RLHF), using the same methods as InstructGPT, but with slight differences in the data collection setup. We trained an initial model using supervised fine-tuning: human AI trainers provided conversations in which they played both sides—the user and an AI assistant. We gave the trainers access to model-written suggestions to help them compose their responses. We mixed this new dialogue dataset with the InstructGPT dataset, which we transformed into a dialogue format.\nTo create a reward model for reinforcement learning, we needed to collect comparison data, which consisted of two or more model responses ranked by quality. To collect this data, we took conversations that AI trainers had with the chatbot. We randomly selected a model-written message, sampled several alternative completions, and had AI trainers rank them. Using these reward models, we can fine-tune the model using Proximal Policy Optimization. We performed several iterations of this process.\n— OpenAI Blog\nFrom its description, we can see that ChatGPT is very similar to InstructGPT. The difference is that, long dialogues are used as dataset to train the model, instead of just prompts and responses data. When humans write the dialogues, they can refer to the model response as a starting point. Trained on this dataset, the model can better understand contexts in long dialogues, and produce answers that are relevant to the context. This is part of the reason why ChatGPT seems to have the impressive ability to remember your previous conversations.\nGPT-4 GPT-4 was released on March 14, 2023. GPT-4 differs from previous GPT models in that it is multi-modal. It accepts both images and texts as inputs and produces texts as outputs. Little is known about its full architecture, but it is probably not much different from GPT-3 and InstructGPT. Here is the only relevant description from the GPT-4 technical report [7]:\nGPT-4 is a Transformer-style model pre-trained to predict the next token in a document, using both publicly available data (such as internet data) and data licensed from third-party providers. The model was then fine-tuned using Reinforcement Learning from Human Feedback (RLHF). Given both the competitive landscape and the safety implications of large-scale models like GPT-4, this report contains no further details about the architecture (including model size), hardware, training compute, dataset construction, training method, or similar.\n— GPT-4 Technical Report, OpenAI\nHowever, one marvelous thing that we are able to see is that they developed infrastructure to reliably predict model performance. They could predict the loss of a very large model, from experiments at much smaller scales, allowing them to quickly try lots of designs and find the best one. A major criticism of deep learning is its black-box nature. Now OpenAI has mastered the alchemy of training deep neural networks. For reaching this step, they must have done much more experiments than any other organization or institution. No doubt they are the best winner so far!\nA core component of this project was developing infrastructure and optimization methods that behave predictably across a wide range of scales. This allowed us to accurately predict some aspects of GPT-4’s performance based on models trained with no more than 1/1,000th the compute of GPT-4.\n— GPT-4 Technical Report, OpenAI\nResources 🌀 Andrej Karpathy has a very good video tutorial on building GPT from scratch, I highly recommend it:\nColab of this tutorial: link🔗 nanoGPT repository: nanoGPT🔗 🌀 LLaMA is an open source alternative to GPT, proposed by Facebook. Lit-LLaMA🔗 is an implementation of LLaMA by Lightning-AI.\n🌀 Huggingface Transformers is a Python library to download and use pre-trained models. There is GPT-2, but no GPT-3 or beyond.\n🌀 Replicate provides APIs to use many vision models.\nIntuitions behind LLMs Why, at this time, deep learning works so well? I’d like to discuss some of my intuitions about LLMs.\nWhat if the data covers 95% of everything If there is only one example of something (e.g. question-answer pair) in the training data, then it could be outnumbered by other data, so either the model won’t remember this example, or it could overfit on it. However, if there are ten, a hundred or even more answers for the same question $q$ in the training data, all of which have similar phrasings, use similar terminologies, and point to similar things, then the model will develop a strong “memory” about it when trained over and over to maximize log likelihood. When the model is asked about this question, it has a good idea about how to output answer that has a high likelihood score: it can generate answers from the “average” of all answers in the training data, and the result will not be far from correct.\nI suspect that most questions submitted to ChatGPT are common ones, and there are already relevant answers on the Internet. It’s like, for a question, Google would return you 100 relevant pages, while ChatGPT would return you one answer that is like the average of the 100 pages. And for uncommon ones or questions that deemed to be harmful, it can simply return “I don’t know” or “I can’t answer that”. So the magic is not all about AI, but more about the data.\nIt is not about finding needles in the ocean Let’s think about next-word prediction. Locally, given a small scope of context, it is often not difficult to infer what the next word is. A large portion of the vocabulary can be eliminated from consideration. The probability distribution only concentrates on a small set of words, and the model only need to learn these simple distributions. From this perspective, it is not too difficult for a model to learn the grammars and produce normal-looking sentences. Words in sentences are not totally independent, but locally, they can often be broke up into independent pieces.\nAnd Transformer on GPU is REALLY good at scaling up this simple idea of guessing the next word from previous words. Inferring the next word from a 4,000-word context is no different than inferring the next word from a 5-word context, the architecture is the same, it’s just that we need to use larger matrices and do more matrix multiplications, but this can be efficiently handled by GPU. So here one is trading compute power for search time. The problem of finding needles in the ocean is converted to compute massive matrix multiplications on the GPU. The Transformer model efficiently addresses the curse of dimensionality problem.\nThe success of ChatGPT is a combination of several factors:\nUnique features of human languages. Progresses in model architectures [10], regularization [11], and optimization algorithms [12] allow for stable training and better generalization. Transformer is efficient, can be scaled up, to trade compute for time. Invest millions of expenditure on data collection. Of course, ChatGPT is not perfect, and can still make simple mistakes. Since logic reasoning is not part of the optimization objective, it will not possess sound logic. Trained only on text data, it also lacks perception about the 3D world, but I speculate that progress will soon be made. The variety of tasks that it can do is already impressive, and its boost to human productivity is undeniable. I’m sure AI models like ChatGPT will become an essential part of the society in the future, just like our cars and phones today.\nPredicting the future: impacts on society It looks like OpenAI is very ambitious. Its goal is not limited to developing large NLP models for dialogues. Rather, it aims to build an entire ecosystem around ChatGPT, where developers and companies all build products around their services. Regardless or whether ChatGPT will become the only super app we will use in the future, it is clear that the dynamics of the tech industry has been shifted. The way we work and live in the future will be different. It takes time, but eventually we will get there.\nMany white-collar jobs will disappear. Many jobs today are “bullshit jobs”. Those jobs are highly repetitive, and do not add much value to the society. People are forced to sit in front of computer screens for 8+ hours and produce tons of garbage everyday.\nOne such job is desktop research, which involves collecting information from various sources on the Internet, and then producing reports so as to sell them to clients. ChatGPT is much better at collecting Internet information. With Plugins, companies can feed their internal documents to an AI model. The model can then retrieve information, answer questions and give advices. In the future, such intelligence collecting services will have much lower and affordable prices.\nAnother job that is probably in danger is data analyst. Basically what a typical data analyst do is writing SQL queries to extract data from databases, and performing data visualization and analytics, e.g. with Python. This job is highly repetitive. Now AI can handle all of that: it can write SQL queries, and it can plot graphs. In the future, if you want insights from data, you might just ask AI in plain English, and it will retrieve data, analyze it and generate report for you. The job may be fully automated. There would be no need to hire someone who remembers all the matplotlib/pandas commands and tricks anymore.\nThere are more. Every job with an “analyst” in its title should be examined against the widespread adoption of AI. One should be cautious with jobs that are not creative but only repetitive. I think entry level jobs in the following list of job categories are going to be threatened by AI. Even if job replacements will not happen very soon, the presence of a productive AI assistant means the difficulty and the skill sets required for those jobs are greatly reduced, so wages are going to be lower and lower, until those jobs disappear altogether.\nMedia jobs (advertising, news editing, journalism) Consultants Lawyers Graphic designers Data analysts Financial analysts Policy analysts Accountants and auditors Replacing repetitive jobs with machines is beneficial for the whole society, because we can stop wasting resources, focus on innovation, produce more, and ultimately improve everyone’s welfare.\nDevelopers now have more power than ever before. Some argue that programming jobs are going to be replaced by AI. That is not accurate. Repetitive works do not have a future in any profession, but entrepreneurship will never cease to prosper. AI has made building applications easier, and that means developers can ship products faster with lower costs. Currently, building a serious full-stack application and delivering it to the market is difficult and time-consuming. It is a team work that requires talents for designs, frontend, backend, marketing, legals and more. Now, with AI that can assist with writing code, designing web pages and logos, drafting marketing campaigns, and composing terms of service for you, you can focus on realizing your ideas and building great products, rather than those business hassles. In the future, it may be possible to ship complicated applications entirely from one individual. Developers will no longer need to rely on big companies for living. They can become CEO of their own. Isn’t it just great?\nChatGPT’s success will further spur AI research. One research direction is to improve model efficiency. Current models are bulky and have high training costs, similar to what computers look like in the 50s and 60s. Maybe we could figure out the exact relationship between data, architecture, and generalization performance. Then we could optimize desired objectives with minimal data and minimal compute. Another research direction is video generation. Current AI models can generate impressive texts and images, but models that can generate videos haven’t been widely adopted. Video data is much richer in dimension, and understanding 3D dynamics is challenging. But I expect significant progress to be made in the near future. Like ChatGPT, the next breakthrough is likely going to come from industry, rather than academics.\nConclusion In this blog post we discussed the technology behind OpenAI’s ChatGPT, as well as its potential impacts on society. GPT is a Transformer model that is trained to predict next word given a long context. Transformers summarize context information as matrix multiplications which can be computed efficiently on GPUs. ChatGPT is pre-trained GPT model fine-tuned on human labeled dialogue dataset. It can greatly boost human productivity, and thus it is a major technology advancement that is going to bring huge revolutions to society.\nReferences [1] Bahdanau, Dzmitry, Kyunghyun Cho, and Yoshua Bengio. “Neural machine translation by jointly learning to align and translate.” arXiv preprint arXiv:1409.0473 (2014).\n[2] Vaswani, Ashish, et al. “Attention is all you need.” Advances in neural information processing systems 30 (2017).\n[3] Radford, Alec, et al. “Improving language understanding by generative pre-training.” OpenAI (2018).\n[4] Radford, Alec, et al. “Language models are unsupervised multitask learners.” OpenAI blog 1.8 (2019): 9.\n[5] Brown, Tom, et al. “Language models are few-shot learners.” Advances in neural information processing systems 33 (2020): 1877-1901.\n[6] Ouyang, Long, et al. “Training language models to follow instructions with human feedback.” arXiv preprint arXiv:2203.02155 (2022).\n[7] OpenAI. “GPT-4 Technical Report.” arXiv preprint arXiv:2303.08774 (2023).\n[8] Touvron, Hugo, et al. “Llama: Open and efficient foundation language models.” arXiv preprint arXiv:2302.13971 (2023).\n[9] Zhu, Yukun, et al. “Aligning books and movies: Towards story-like visual explanations by watching movies and reading books.” Proceedings of the IEEE international conference on computer vision (2015): 19-27.\n[10] He, Kaiming, et al. “Deep residual learning for image recognition.” Proceedings of the IEEE conference on computer vision and pattern recognition (2016).\n[11] Ba, Jimmy Lei, Jamie Ryan Kiros, and Geoffrey E. Hinton. “Layer normalization.” arXiv preprint arXiv:1607.06450 (2016).\n[12] Kingma, Diederik P., and Jimmy Ba. “Adam: A method for stochastic optimization.” arXiv preprint arXiv:1412.6980 (2014).\n","wordCount":"4535","inLanguage":"en","image":"https://lifei.ai/imgs/chatgpt/cover.jpeg","datePublished":"2023-04-06T00:00:00Z","dateModified":"2023-04-06T00:00:00Z","author":{"@type":"Person","name":"Fei Li"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://lifei.ai/posts/2023-04-06-chatgpt/"},"publisher":{"@type":"Organization","name":"lifei.ai | AI blogs","logo":{"@type":"ImageObject","url":"https://lifei.ai/favicon.ico"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://lifei.ai/ accesskey=h title="lifei.ai (Alt + H)"><img src=https://lifei.ai/f.png alt aria-label=logo height=40>lifei.ai</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://lifei.ai/archives/ title=Archives><span>Archives</span></a></li><li><a href=https://lifei.ai/tags/ title=Tags><span>Tags</span></a></li><li><a href=https://lifei.ai/search/ title="Search (Alt + /)" accesskey=/><span>Search</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://lifei.ai/>Home</a>&nbsp;»&nbsp;<a href=https://lifei.ai/posts/>Posts</a></div><h1 class="post-title entry-hint-parent">ChatGPT has taken the world by storm. What's Next?</h1><div class=post-meta><span title='2023-04-06 00:00:00 +0000 UTC'>April 6, 2023</span>&nbsp;·&nbsp;22 min&nbsp;·&nbsp;Fei Li</div></header><figure class=entry-cover><img loading=eager src=https://lifei.ai/imgs/chatgpt/cover.jpeg alt="ChatGPT cover"></figure><div class=toc><details open><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><nav id=TableOfContents><ul><li><a href=#the-models>The Models</a><ul><li><a href=#gpt>GPT</a></li><li><a href=#gpt-2>GPT-2</a></li><li><a href=#gpt-3>GPT-3</a></li><li><a href=#instructgpt>InstructGPT</a></li><li><a href=#chatgpt>ChatGPT</a></li><li><a href=#gpt-4>GPT-4</a></li></ul></li><li><a href=#resources>Resources</a></li><li><a href=#intuitions-behind-llms>Intuitions behind LLMs</a><ul><li><a href=#what-if-the-data-covers-95-of-everything>What if the data covers 95% of everything</a></li><li><a href=#it-is-not-about-finding-needles-in-the-ocean>It is not about finding needles in the ocean</a></li></ul></li><li><a href=#predicting-the-future-impacts-on-society>Predicting the future: impacts on society</a></li><li><a href=#conclusion>Conclusion</a></li><li><a href=#references>References</a></li></ul></nav></div></details></div><div class=post-content><p>On April 11, 2022, I wrote <a href=https://lifeitech.github.io/posts/attention-and-transformers/#summary--whats-next>the following</a>:</p><p>&ldquo;<em>While current models may still have limited capacity, I&rsquo;m optimistic that, we should see better and better AI models coming out in the future, and one day machines can have enough intelligence to handle tasks and jobs we do today.</em>&rdquo;</p><p>7 months later, OpenAI released ChatGPT, the performance of which has stunned the public. It can chat, write stories, debug code&mldr;there hasn&rsquo;t been a chatbot that is so intelligent and so fluent in dialogues with human. Previously, AI applications are largely <em>passive</em>: think about face recognition, speech recognition, OCR, autonomous driving, recommendation systems&mldr;they are deployed largely in the backstage and are not something that people directly interact with. ChatGPT is different: it is like a person that everyone can talk to at any time. Its interactive nature quickly lets it become popular around the world.</p><p>As we will see, there is not much magic behind ChatGPT. Its building block is Attentions <a href=#1>[1]</a> and Transformers <a href=#2>[2]</a>, which were proposed in 2014 and 2017 respectively, so ChatGPT didn&rsquo;t employ any radically new technologies. Here is a high-level summary of their approach: First, a large neural network model is trained on Internet data to predict the next word. Then it is fine-tuned on prompt-response dialogue dataset created by human labelers. Its generated responses to prompts are then evaluated by humans, and the model is further trained to maximize human evaluation score. That&rsquo;s basically it. However, idea is one thing, and how to scale an idea to make it work in real world is another. What is truly marvelous about OpenAI is their exceptional engineering efforts, from data collection to training, monitoring, and deployments. Never underestimate the investments required to make something like ChatGPT!</p><h2 id=the-models>The Models<a hidden class=anchor aria-hidden=true href=#the-models>#</a></h2><table><thead><tr><th>Model</th><th>Date</th><th>Size</th></tr></thead><tbody><tr><td>GPT</td><td>June 2018</td><td>117M</td></tr><tr><td>GPT-2</td><td>February 2019</td><td>1.5B</td></tr><tr><td>GPT-3</td><td>May 2020</td><td>175B</td></tr><tr><td>ChatGPT</td><td>Nov 2022</td><td>undisclosed</td></tr><tr><td>GPT-4</td><td>March 2023</td><td>undisclosed</td></tr></tbody></table><h3 id=gpt>GPT<a hidden class=anchor aria-hidden=true href=#gpt>#</a></h3><p>GPT <a href=#3>[3]</a> is not very complicated. It is a transformer model. All it does is to output a probability distribution over the next word given the input context. To generate next word, one selects the word with the highest probability. Here is a snapshot from the paper:</p><figure class=align-center><img loading=lazy src=/imgs/chatgpt/gpt.png#center alt="GPT model"><figcaption><p>GPT model</p></figcaption></figure><p>Given previous context $[u_{i-k}&mldr;u_{i-1}]$, the simplest way to generate the next word $u_i$ is to assume that it only depends on its left neighbor $u_{i-1}$, count the occurrence of all words that come after $u_{i-1}$ in the training corpus, and then select the word with the highest frequency. This is the 2-gram model we talked about <a href=https://lifeitech.github.io/posts/nlp-prob-ngram/>earlier</a>.</p><p>To model context dependence, we need something more sophisticated than that. The Attention model <a href=#1>[1]</a> is the exact opposite of the Markov assumption of context independence. It is a simple and efficient way to pay attention to previous context when generating the next word. An output $u_i$ is a weighted sum of all the words in its context $(u_{i-1},\ldots,u_{i-k})$:</p><p>$$
u_i = \alpha_1 v_{i-1} + \alpha_2 v_{i-2} + \cdots + \alpha_k v_{i-k},
$$</p><p>where the weight $\alpha_i$ represents how much the output should pay attention to $u_i$, and $v_k=Vu_{i-k}$ with learnable parameter matrix $V$. See <a href=https://lifeitech.github.io/posts/attention-and-transformers/>this post</a> for detail. This way,</p><ul><li>the computation is easily parallelizable, so is very suitable for GPU computation;</li><li>can easily scale to long contexts, for example 3000 tokens or even more;</li><li>can easily scale up model size.</li></ul><p>Not all model architectures in deep learning are easily scalable. Scalability is clearly one of the biggest advantages of the Attention model.</p><p>The Transformer model <a href=#2>[2]</a> is attention layer plus residual layer, linear layer and normalization.</p><figure class=align-center><img loading=lazy src=/imgs/chatgpt/transformer.png#center alt="Transformer model architecture"><figcaption><p>Transformer model architecture</p></figcaption></figure><p>Those extra components are also indispensable:</p><ul><li>Residual connections ensure that gradients can directly flow backward from output to input. Without it convergence is often difficult.</li><li>Normalization addresses over-fitting and ensures robust learning. Without it training loss can easily explode.</li><li>Linear layers add more parameters, increasing model capacities. Without it the loss will be higher, performance will be much worse.</li></ul><p>And here you are. 12 layers of Transformer blocks. That&rsquo;s basically GPT.</p><p>In those days, fine-tuning on downstream tasks is standard practice. To apply GPT in each kind of problem, it has to be fine-tuned on each kind of such dataset. Here is a description from the paper <a href=#3>[3]</a>:</p><blockquote><p>After training the model with the objective, we adapt the parameters to the supervised target task&mldr;we assume a labeled dataset $\mathcal{C}$, where each instance consists of a sequence of tokens, $x^1,\ldots,x^m$, along with a label $y$. The inputs are passed through our pre-trained model to obtain the final transformer block&rsquo;s activation $h_l^m$, which is then fed into an added linear output layer with parameters $W_y$ to predict $y$:</p><p>$$P(y \mid x^1,\ldots,x^m) = \texttt{softmax}(h_l^mW_y).$$</p><p>This gives us the following objective to maximize:
$$L_2(\mathcal{C}) = \sum_{(x,y)}\log P(y\mid x^1,\ldots,x^m).$$</p></blockquote><p>Since GPT only accepts sequences of fixed length as inputs, training data has to be structured as sequences, with delimiters separating different sections of input. For example, for question answering task, context and choices are delimited before feeding to the model.</p><figure class=align-center><img loading=lazy src=/imgs/chatgpt/fine-tune.png#center alt="To fine-tune GPT on downstream tasks, inputs in datasets have to be transformed to sequence-like structures."><figcaption><p>To fine-tune GPT on downstream tasks, inputs in datasets have to be transformed to sequence-like structures.</p></figcaption></figure><p>If a model is trained on large enough data, does it need fine-tuning at all? GPT-2 brought up this idea of &ldquo;zero-shot&rdquo;, which was a novel practice at that time.</p><h3 id=gpt-2>GPT-2<a hidden class=anchor aria-hidden=true href=#gpt-2>#</a></h3><p>The GPT-2 <a href=#4>[4]</a> model architecture is the same as GPT: Transformers. Beside the differences below, it is basically a larger version of GPT:</p><ol><li>GPT-2 was trained on a much larger dataset. GPT model was trained on the BooksCorpus <a href=#9>[9]</a> dataset. In GPT-2, they scaped the Internet and created a dataset called WebText, which contains 8 million documents for a size of 40 GB.</li><li>In GPT-2, layer normalization was moved to the <em>beginning</em>, rather than the end of each sub-block.</li><li>An additional layer normalization was added after the <em>final</em> self-attention block.</li><li>Context size was increased from 512 to <em>1024</em> tokens.</li></ol><p>These changes played very important roles in improving model performance. But the most significant paradigm shift from GPT to GPT-2 is <strong>zero-shot</strong>. The authors realized that, with enough training data, the model can learn various tasks directly from the dataset, without any explicit supervision (hence the title &ldquo;Language Models are Unsupervised Multitask Learners&rdquo;).</p><p>Supervised learning and unsupervised or generative learning are not a dichotomy. On the one hand, generative learning is disguised supervised learning. Generative training on text sequences can be seen as repeatedly applying supervised learning to predict a label (the next word) given some text input (context). On the other hand, some supervised learning tasks can be formulated as generative learning tasks. For example, as mentioned in <a href=#4>[4]</a>, for translation, instead of training on <code>(english, french)</code> input and output pairs, a generative model can be trained on <code>(translate to french, english text, french text)</code> sequences. If the model possesses enough context learning ability, and if such tasks appear naturally and abundantly in the training corpus, which is the case, then we can expect the model to possess at least some language translation ability after training. The two are different ways to formulate the same thing: make predictions given inputs.</p><figure class=align-center><img loading=lazy src=/imgs/chatgpt/gpt2-data.png#center alt="An example in GPT-2 paper showing naturally occurring language translation pairs found in training dataset" width=400><figcaption><p>An example in GPT-2 paper showing naturally occurring language translation pairs found in training dataset</p></figcaption></figure><p>However, generative training on vast amount of unlabeled data provides advantages over supervised training on well-prepared labeled data $(x,y)$. The effort to prepare such labeled data is expensive, labor-intensive and time-consuming, and is also hard to scale up. Let&rsquo;s take a thought experiment. Suppose supervised learning has 80% efficiency of learning from labeled data, while unsupervised learning has only 20% efficiency of learning from unlabeled data. Even though labeled data provide greater learning efficiency than that of unlabeled data, if the amount of unlabeled data greatly surpasses that of labeled data, then eventually an unsupervised learning model will become more powerful than a supervised one trained on far less amount of data. What&rsquo;s more, a generative model trained on vast and diverse source of texts can pick up multiple abilities from data, while a supervised one can only perform that one specific task defined by the training dataset $\{(x_i,y_i)\}_{i=1}^{N}$.</p><p>GPT-2 is the starting point where we later see amazing performance of generative AI. When the model size gets larger, the performance continues to get better. There is no reason to stop training models with larger sizes.</p><figure class=align-center><img loading=lazy src=/imgs/chatgpt/gpt2-scaling.png#center alt="As model size gets larger, performance gets better."><figcaption><p>As model size gets larger, performance gets better.</p></figcaption></figure><h3 id=gpt-3>GPT-3<a hidden class=anchor aria-hidden=true href=#gpt-3>#</a></h3><p>GPT-3 <a href=#5>[5]</a> largely shares the same architecture as GPT-2, but is significantly larger, with 175B parameters. For reference, here is a short description from the paper:</p><blockquote><p>We use the same model and architecture as GPT-2 &mldr;&mldr; with the exception that we use alternating dense and locally banded sparse attention patterns in the layers of the transformer, similar to the Sparse Transformer.</p></blockquote><p>The most silent aspect of the GPT-3 paper is that an extensive series of experiments were conducted, and the GPT-3 model achieved strong performances across multiple tasks. The experiments strongly suggest that scaling up model size is the way to obtain better performance.</p><figure class=align-center><img loading=lazy src=/imgs/chatgpt/gpt3-scaling.png#center alt="There is no end in scaling"><figcaption><p>There is no end in scaling</p></figcaption></figure><figure class=align-center><img loading=lazy src=/imgs/chatgpt/gpt3-scaling-arithmetic.png#center alt="There is no end in scaling"><figcaption><p>There is no end in scaling</p></figcaption></figure><figure class=align-center><img loading=lazy src=/imgs/chatgpt/gpt3-scaling-lambada.png#center alt="There is no end in scaling"><figcaption><p>There is no end in scaling</p></figcaption></figure><figure class=align-center><img loading=lazy src=/imgs/chatgpt/gpt3-scaling-qa.png#center alt="There is no end in scaling"><figcaption><p>There is no end in scaling</p></figcaption></figure><figure class=align-center><img loading=lazy src=/imgs/chatgpt/gpt3-scaling-translation.png#center alt="There is no end in scaling"><figcaption><p>There is no end in scaling</p></figcaption></figure><figure class=align-center><img loading=lazy src=/imgs/chatgpt/gpt3-scaling-nlp.png#center alt="There is no end in scaling"><figcaption><p>There is no end in scaling</p></figcaption></figure><p>GPT-3 is able to write stories and news articles. It was pretty impressive at that point, and caught some public attention. But still it was not something that anyone can directly interact with, so many people were still not aware of it.</p><h3 id=instructgpt>InstructGPT<a hidden class=anchor aria-hidden=true href=#instructgpt>#</a></h3><p>GPT-3 is optimized to produce web-like documents. If you give the model an instruction, like &ldquo;explain &mldr;. to me&rdquo;, it will not know how to respond to this particular instruction, but instead it is likely to produce something that looks like articles that contain similar sentences in the training data. In OpenAI&rsquo;s term, the model is <em>misaligned</em>.</p><p>InstructGPT <a href=#6>[6]</a> addresses this problem by resorting to supervised fine-tuning. Below is an overview of the approach from the paper. Step 1 is to fine-tune on high quality human-crafted instruction-response dataset. Step 2 is to train a reward model, and step 3 is to train the model to maximize reward model output. The last two steps are called Reinforcement Learning with Human Feedback (RLHF), which proves to be an effective way of aligning model to human instructions. It shares similarity with <strong>GAN</strong>, in which a generative model is trained to optimize output score from a discriminative model. In GAN the two models are trained concurrently. Here in InstructGPT the two models are trained separately.</p><figure class=align-center><img loading=lazy src=/imgs/chatgpt/instructGPT.png#center alt="InstructGPT. (1) A pre-trained LM is fine-tuned using supervised learning on human-written dataset. (2) Collect human rankings on model outputs and train a discriminative model on this dataset. (3) Train the fine-tuned LM so that its generated responses to prompts maximize the discriminative model&amp;rsquo;s output."><figcaption><p>InstructGPT. (1) A pre-trained LM is fine-tuned using supervised learning on human-written dataset. (2) Collect human rankings on model outputs and train a discriminative model on this dataset. (3) Train the fine-tuned LM so that its generated responses to prompts maximize the discriminative model&rsquo;s output.</p></figcaption></figure><p>Here are the methods in detail:</p><ol><li><p>First, a pre-trained GPT-3 model is fine-tuned on prompt-response dataset created by 40 labelers. The dataset contains about 13k training prompts. The fine-tuned model is called SFT (which stands for &ldquo;Supervised Fine-Tuning&rdquo;).</p></li><li><p>Second, given a prompt, sample several outputs (from $K=4$ to $K=9$) from the model. A human labeler then ranks the outputs. Collect such human ranking dataset, and train a reward model (RM) on the dataset. In InstructGPT paper <a href=#6>[6]</a>, the RM model is a GPT-3 model with 6B parameters. The training objective is the pairwise ranking loss</p></li></ol><p>$$
\text{loss}(\theta) = -\frac{1}{K \choose 2} E_{(x, y_w, y_l)\sim D}[\log(\sigma(r_\theta(x,y_w) - r_\theta(x, y_l)))]
$$</p><p>where $r_\theta(x, y)$ is the scalar output of the reward model for prompt $x$ and completion $y$ with parameters $\theta$, $y_w$ is the preferred completion out of the pair of $y_w$ and $y_l$, and $D$ is the dataset of human comparisons. The RM dataset has 33k training prompts.</p><ol start=3><li>Finally, fine-tune the SFT model again, such that its output will have a high reward score from the RM model. This is called Proxy Policy Optimization (PPO) in InstructGPT paper <a href=#6>[6]</a>, which is about optimizing (maximizing) the following objective:</li></ol><p>$$
\text{objective}(\phi) = E_{(x,y)\sim D_{\pi_\phi^{RL}}}[r_\theta(x,y) - \beta\log\left(\pi_\phi^{RL}(y\mid x) / \pi^{SFT}(y\mid x)\right)] + \gamma E_{x\sim D_{\text{pretrain}}}[\log(\pi_\phi^{RL}(x))].
$$</p><p>Here, $\pi^{SFT}$ is the fine-tuned model from step 1, which is kept fixed, and $\pi_{\phi}^{RL}$ (called &ldquo;RL policy&rdquo;) is a copy of $\pi^{SFT}$ whose parameters are going to be updated by training. $x$ is prompt, and $y$ is the response output from the model.</p><p>The first term is the main objective we want to maximize. Note that, sampling comes from the model we are training, rather than a fixed dataset. After gradient updates, the sample distribution will be different.</p><p>The second term (negative KL divergence between distribution $\pi_\phi^{RL}(y\mid x)$ and $\pi^{SFT}(y\mid x)$) is a regularization term that penalizes deviation from the fine-tuned model from step 1. This is added to avoid losing all the information stored in the weights of the fine-tuned model.</p><p>The third term is also a regularization term. It is the objective of language modeling (maximizing log likelihood on next word). This is to prevent the model from focusing too much on increasing $r_\theta(x,y)$ and forgetting about next-word generation.</p><h3 id=chatgpt>ChatGPT<a hidden class=anchor aria-hidden=true href=#chatgpt>#</a></h3><p>ChatGPT was released on November 30, 2022, and soon caused a technology revolution around the world. Numerous applications like <a href=https://copy.ai>copy.ai</a> and <a href=https://typeface.ai>typeface.ai</a> quickly emerged. I was impressed by how LLMs can dramatically boost human productivity. The point is not about whether ChatGPT will make not mistake and always give accurate answers. Rather, the point is that, it showed us how AI can have huge <em>potential impacts</em> on society.</p><p>Regarding model details, at this point, OpenAI is no longer open anymore. It didn&rsquo;t publish research paper on ChatGPT. We can only infer information about the model from its <a href=https://openai.com/blog/chatgpt>blog</a>:</p><blockquote><p><strong>Methods</strong></p><p>We trained this model using Reinforcement Learning from Human Feedback (RLHF), using the same methods as InstructGPT, but with slight differences in the data collection setup. We trained an initial model using supervised fine-tuning: human AI trainers provided conversations in which they played both sides—the user and an AI assistant. We gave the trainers access to model-written suggestions to help them compose their responses. We mixed this new dialogue dataset with the InstructGPT dataset, which we transformed into a dialogue format.</p><p>To create a reward model for reinforcement learning, we needed to collect comparison data, which consisted of two or more model responses ranked by quality. To collect this data, we took conversations that AI trainers had with the chatbot. We randomly selected a model-written message, sampled several alternative completions, and had AI trainers rank them. Using these reward models, we can fine-tune the model using Proximal Policy Optimization. We performed several iterations of this process.</p><p>&mdash; OpenAI Blog</p></blockquote><p>From its description, we can see that ChatGPT is very similar to InstructGPT. The difference is that, long dialogues are used as dataset to train the model, instead of just prompts and responses data. When humans write the dialogues, they can refer to the model response as a starting point. Trained on this dataset, the model can better understand contexts in long dialogues, and produce answers that are relevant to the context. This is part of the reason why ChatGPT seems to have the impressive ability to remember your previous conversations.</p><h3 id=gpt-4>GPT-4<a hidden class=anchor aria-hidden=true href=#gpt-4>#</a></h3><p>GPT-4 was released on March 14, 2023. GPT-4 differs from previous GPT models in that it is <em>multi-modal</em>. It accepts both images and texts as inputs and produces texts as outputs. Little is known about its full architecture, but it is probably not much different from GPT-3 and InstructGPT. Here is the only relevant description from the GPT-4 technical report <a href=#7>[7]</a>:</p><blockquote><p>GPT-4 is a Transformer-style model pre-trained to predict the next token in a document, using both publicly available data (such as internet data) and data licensed from third-party providers. The model was then fine-tuned using Reinforcement Learning from Human Feedback (RLHF). Given both the competitive landscape and the safety implications of large-scale models like GPT-4, this report contains no further details about the architecture (including model size), hardware, training compute, dataset construction, training method, or similar.</p><p>&mdash; GPT-4 Technical Report, OpenAI</p></blockquote><p>However, one marvelous thing that we <em>are</em> able to see is that they developed infrastructure to reliably <em>predict</em> model performance. They could predict the loss of a very large model, from experiments at much smaller scales, allowing them to quickly try lots of designs and find the best one. A major criticism of deep learning is its black-box nature. Now OpenAI has mastered the alchemy of training deep neural networks. For reaching this step, they must have done much more experiments than any other organization or institution. No doubt they are the best winner so far!</p><blockquote><p>A core component of this project was developing infrastructure and optimization methods that behave predictably across a wide range of scales. This allowed us to accurately predict some aspects of GPT-4’s performance based on models trained with no more than 1/1,000th the compute of GPT-4.</p><p>&mdash; GPT-4 Technical Report, OpenAI</p></blockquote><h2 id=resources>Resources<a hidden class=anchor aria-hidden=true href=#resources>#</a></h2><p>🌀 <a href=https://karpathy.ai/>Andrej Karpathy</a> has a very good video tutorial on building GPT from scratch, I highly recommend it:</p><div style=position:relative;padding-bottom:56.25%;height:0;overflow:hidden><iframe src=https://www.youtube.com/embed/kCc8FmEb1nY style=position:absolute;top:0;left:0;width:100%;height:100%;border:0 allowfullscreen title="YouTube Video"></iframe></div><ul><li>Colab of this tutorial: <a href="https://colab.research.google.com/drive/1JMLa53HDuA-i7ZBmqV7ZnA3c_fvtXnx-?usp=sharing">link</a>🔗</li><li>nanoGPT repository: <a href=https://github.com/karpathy/nanoGPT>nanoGPT</a>🔗</li></ul><p>🌀 <a href=https://github.com/facebookresearch/llama>LLaMA</a> is an open source alternative to GPT, proposed by Facebook. <a href=https://github.com/Lightning-AI/lit-llama>Lit-LLaMA</a>🔗 is an implementation of LLaMA by Lightning-AI.</p><p>🌀 <a href=https://huggingface.co/models>Huggingface Transformers</a> is a Python library to download and use pre-trained models. There is GPT-2, but no GPT-3 or beyond.</p><p>🌀 <a href=https://replicate.com/>Replicate</a> provides APIs to use many vision models.</p><h2 id=intuitions-behind-llms>Intuitions behind LLMs<a hidden class=anchor aria-hidden=true href=#intuitions-behind-llms>#</a></h2><p>Why, at this time, deep learning works so well? I&rsquo;d like to discuss some of my intuitions about LLMs.</p><h3 id=what-if-the-data-covers-95-of-everything>What if the data covers 95% of everything<a hidden class=anchor aria-hidden=true href=#what-if-the-data-covers-95-of-everything>#</a></h3><p>If there is only one example of something (e.g. question-answer pair) in the training data, then it could be outnumbered by other data, so either the model won&rsquo;t remember this example, or it could overfit on it. However, if there are ten, a hundred or even more answers for the same question $q$ in the training data, all of which have similar phrasings, use similar terminologies, and point to similar things, then the model will develop a strong &ldquo;memory&rdquo; about it when trained over and over to maximize log likelihood. When the model is asked about this question, it has a good idea about how to output answer that has a high likelihood score: it can generate answers from the &ldquo;average&rdquo; of all answers in the training data, and the result will not be far from correct.</p><p>I suspect that most questions submitted to ChatGPT are common ones, and there are already relevant answers on the Internet. It&rsquo;s like, for a question, Google would return you 100 relevant pages, while ChatGPT would return you one answer that is like the average of the 100 pages. And for uncommon ones or questions that deemed to be harmful, it can simply return &ldquo;I don&rsquo;t know&rdquo; or &ldquo;I can&rsquo;t answer that&rdquo;. So the magic is not all about AI, but more about the data.</p><h3 id=it-is-not-about-finding-needles-in-the-ocean>It is not about finding needles in the ocean<a hidden class=anchor aria-hidden=true href=#it-is-not-about-finding-needles-in-the-ocean>#</a></h3><p>Let&rsquo;s think about next-word prediction. Locally, given a small scope of context, it is often not difficult to infer what the next word is. A large portion of the vocabulary can be eliminated from consideration. The probability distribution only concentrates on a small set of words, and the model only need to learn these simple distributions. From this perspective, it is not too difficult for a model to learn the grammars and produce normal-looking sentences. Words in sentences are not totally independent, but locally, they can often be broke up into independent pieces.</p><p>And Transformer on GPU is REALLY good at scaling up this simple idea of guessing the next word from previous words. Inferring the next word from a 4,000-word context is <em>no different</em> than inferring the next word from a 5-word context, the architecture is the same, it&rsquo;s just that we need to use larger matrices and do more matrix multiplications, but this can be efficiently handled by GPU. So here one is trading compute power for search time. The problem of finding needles in the ocean is converted to compute massive matrix multiplications on the GPU. The Transformer model efficiently addresses the curse of dimensionality problem.</p><p>The success of ChatGPT is a combination of several factors:</p><ol><li>Unique features of human languages.</li><li>Progresses in model architectures <a href=#10>[10]</a>, regularization <a href=#11>[11]</a>, and optimization algorithms <a href=#12>[12]</a> allow for stable training and better generalization.</li><li>Transformer is efficient, can be scaled up, to trade compute for time.</li><li>Invest millions of expenditure on data collection.</li></ol><p>Of course, ChatGPT is not perfect, and can still make simple mistakes. Since logic reasoning is not part of the optimization objective, it <em>will not</em> possess sound logic. Trained only on text data, it also lacks perception about the 3D world, but I speculate that progress will soon be made. The variety of tasks that it can do is already impressive, and its boost to human productivity is undeniable. I&rsquo;m sure AI models like ChatGPT will become an essential part of the society in the future, just like our cars and phones today.</p><h2 id=predicting-the-future-impacts-on-society>Predicting the future: impacts on society<a hidden class=anchor aria-hidden=true href=#predicting-the-future-impacts-on-society>#</a></h2><p>It looks like OpenAI is very ambitious. Its goal is not limited to developing large NLP models for dialogues. Rather, it aims to build an entire <em>ecosystem</em> around ChatGPT, where developers and companies all build products around their services. Regardless or whether ChatGPT will become the only super app we will use in the future, it is clear that the dynamics of the tech industry has been shifted. The way we work and live in the future will be different. It takes time, but eventually we will get there.</p><p><strong>Many white-collar jobs will disappear.</strong> Many jobs today are <a href=https://en.wikipedia.org/wiki/Bullshit_Jobs>&ldquo;bullshit jobs&rdquo;</a>. Those jobs are highly repetitive, and do not add much value to the society. People are forced to sit in front of computer screens for 8+ hours and produce tons of garbage everyday.</p><p>One such job is desktop research, which involves collecting information from various sources on the Internet, and then producing reports so as to sell them to clients. ChatGPT is much better at collecting Internet information. With <a href=https://openai.com/blog/chatgpt-plugins>Plugins</a>, companies can feed their internal documents to an AI model. The model can then retrieve information, answer questions and give advices. In the future, such intelligence collecting services will have much lower and affordable prices.</p><p>Another job that is probably in danger is data analyst. Basically what a typical data analyst do is writing SQL queries to extract data from databases, and performing data visualization and analytics, e.g. with Python. This job is highly repetitive. Now AI can handle all of that: it can write SQL queries, and it can <a href=https://openai.com/blog/chatgpt-plugins>plot graphs</a>. In the future, if you want insights from data, you might just ask AI in plain English, and it will retrieve data, analyze it and generate report for you. The job may be fully automated. There would be no need to hire someone who remembers all the matplotlib/pandas commands and tricks anymore.</p><p>There are more. Every job with an &ldquo;analyst&rdquo; in its title should be examined against the widespread adoption of AI. One should be cautious with jobs that are not creative but only repetitive. I think entry level jobs in the following list of job categories are going to be threatened by AI. Even if job replacements will not happen very soon, the presence of a productive AI assistant means the difficulty and the skill sets required for those jobs are greatly reduced, so wages are going to be lower and lower, until those jobs disappear altogether.</p><ul><li>Media jobs (advertising, news editing, journalism)</li><li>Consultants</li><li>Lawyers</li><li>Graphic designers</li><li>Data analysts</li><li>Financial analysts</li><li>Policy analysts</li><li>Accountants and auditors</li></ul><p>Replacing repetitive jobs with machines is beneficial for the whole society, because we can stop wasting resources, focus on innovation, produce more, and ultimately improve everyone&rsquo;s welfare.</p><p><strong>Developers now have more power than ever before.</strong> Some argue that programming jobs are going to be replaced by AI. That is not accurate. Repetitive works do not have a future in any profession, but entrepreneurship will never cease to prosper. AI has made building applications easier, and that means developers can ship products faster with lower costs. Currently, building a serious full-stack application and delivering it to the market is difficult and time-consuming. It is a team work that requires talents for designs, frontend, backend, marketing, legals and more. Now, with AI that can assist with writing code, designing web pages and logos, drafting marketing campaigns, and composing terms of service for you, you can focus on realizing your ideas and building great products, rather than those business hassles. In the future, it may be possible to ship complicated applications entirely from one individual. Developers will no longer need to rely on big companies for living. They can become CEO of their own. Isn&rsquo;t it just great?</p><p><strong>ChatGPT&rsquo;s success will further spur AI research.</strong> One research direction is to improve model efficiency. Current models are bulky and have high training costs, similar to what computers look like in the 50s and 60s. Maybe we could figure out the exact relationship between data, architecture, and generalization performance. Then we could optimize desired objectives with minimal data and minimal compute. Another research direction is video generation. Current AI models can generate impressive texts and images, but models that can generate videos haven&rsquo;t been widely adopted. Video data is much richer in dimension, and understanding 3D dynamics is challenging. But I expect significant progress to be made in the near future. Like ChatGPT, the next breakthrough is likely going to come from industry, rather than academics.</p><h2 id=conclusion>Conclusion<a hidden class=anchor aria-hidden=true href=#conclusion>#</a></h2><p>In this blog post we discussed the technology behind OpenAI&rsquo;s ChatGPT, as well as its potential impacts on society. GPT is a Transformer model that is trained to predict next word given a long context. Transformers summarize context information as matrix multiplications which can be computed efficiently on GPUs. ChatGPT is pre-trained GPT model fine-tuned on human labeled dialogue dataset. It can greatly boost human productivity, and thus it is a major technology advancement that is going to bring huge revolutions to society.</p><h2 id=references>References<a hidden class=anchor aria-hidden=true href=#references>#</a></h2><p>[1] Bahdanau, Dzmitry, Kyunghyun Cho, and Yoshua Bengio. &ldquo;Neural machine translation by jointly learning to align and translate.&rdquo; <em>arXiv preprint arXiv:1409.0473</em> (2014).</p><p>[2] Vaswani, Ashish, et al. &ldquo;Attention is all you need.&rdquo; <em>Advances in neural information processing systems</em> 30 (2017).</p><p>[3] Radford, Alec, et al. &ldquo;Improving language understanding by generative pre-training.&rdquo; <em>OpenAI</em> (2018).</p><p>[4] Radford, Alec, et al. &ldquo;Language models are unsupervised multitask learners.&rdquo; <em>OpenAI blog</em> 1.8 (2019): 9.</p><p>[5] Brown, Tom, et al. &ldquo;Language models are few-shot learners.&rdquo; <em>Advances in neural information processing systems</em> 33 (2020): 1877-1901.</p><p>[6] Ouyang, Long, et al. &ldquo;Training language models to follow instructions with human feedback.&rdquo; <em>arXiv preprint arXiv:2203.02155</em> (2022).</p><p>[7] OpenAI. &ldquo;GPT-4 Technical Report.&rdquo; <em>arXiv preprint arXiv:2303.08774</em> (2023).</p><p>[8] Touvron, Hugo, et al. &ldquo;Llama: Open and efficient foundation language models.&rdquo; <em>arXiv preprint arXiv:2302.13971</em> (2023).</p><p>[9] Zhu, Yukun, et al. &ldquo;Aligning books and movies: Towards story-like visual explanations by watching movies and reading books.&rdquo; <em>Proceedings of the IEEE international conference on computer vision</em> (2015): 19-27.</p><p>[10] He, Kaiming, et al. &ldquo;Deep residual learning for image recognition.&rdquo; <em>Proceedings of the IEEE conference on computer vision and pattern recognition</em> (2016).</p><p>[11] Ba, Jimmy Lei, Jamie Ryan Kiros, and Geoffrey E. Hinton. &ldquo;Layer normalization.&rdquo; <em>arXiv preprint arXiv:1607.06450</em> (2016).</p><p>[12] Kingma, Diederik P., and Jimmy Ba. &ldquo;Adam: A method for stochastic optimization.&rdquo; arXiv preprint arXiv:1412.6980 (2014).</p></div><footer class=post-footer><ul class=post-tags><li><a href=https://lifei.ai/tags/gpt/>gpt</a></li><li><a href=https://lifei.ai/tags/chatgpt/>chatgpt</a></li><li><a href=https://lifei.ai/tags/nlp/>nlp</a></li></ul><nav class=paginav><a class=prev href=https://lifei.ai/posts/2023-08-31-better-transformers/><span class=title>« Prev</span><br><span>Better Transformers</span></a>
<a class=next href=https://lifei.ai/posts/2023-04-04-jekyll-to-hugo/><span class=title>Next »</span><br><span>Why I Switched to Hugo</span></a></nav><ul class=share-buttons><li><a target=_blank rel="noopener noreferrer" aria-label="share ChatGPT has taken the world by storm. What's Next? on x" href="https://x.com/intent/tweet/?text=ChatGPT%20has%20taken%20the%20world%20by%20storm.%20What%27s%20Next%3f&amp;url=https%3a%2f%2flifei.ai%2fposts%2f2023-04-06-chatgpt%2f&amp;hashtags=gpt%2cchatgpt%2cnlp"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M512 62.554V449.446C512 483.97 483.97 512 449.446 512H62.554C28.03 512 0 483.97.0 449.446V62.554C0 28.03 28.029.0 62.554.0H449.446C483.971.0 512 28.03 512 62.554zM269.951 190.75 182.567 75.216H56L207.216 272.95 63.9 436.783h61.366L235.9 310.383l96.667 126.4H456L298.367 228.367l134-153.151H371.033zM127.633 110h36.468l219.38 290.065H349.5z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share ChatGPT has taken the world by storm. What's Next? on linkedin" href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https%3a%2f%2flifei.ai%2fposts%2f2023-04-06-chatgpt%2f&amp;title=ChatGPT%20has%20taken%20the%20world%20by%20storm.%20What%27s%20Next%3f&amp;summary=ChatGPT%20has%20taken%20the%20world%20by%20storm.%20What%27s%20Next%3f&amp;source=https%3a%2f%2flifei.ai%2fposts%2f2023-04-06-chatgpt%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM160.461 423.278V197.561h-75.04v225.717h75.04zm270.539.0V293.839c0-69.333-37.018-101.586-86.381-101.586-39.804.0-57.634 21.891-67.617 37.266v-31.958h-75.021c.995 21.181.0 225.717.0 225.717h75.02V297.222c0-6.748.486-13.492 2.474-18.315 5.414-13.475 17.767-27.434 38.494-27.434 27.135.0 38.007 20.707 38.007 51.037v120.768H431zM123.448 88.722C97.774 88.722 81 105.601 81 127.724c0 21.658 16.264 39.002 41.455 39.002h.484c26.165.0 42.452-17.344 42.452-39.002-.485-22.092-16.241-38.954-41.943-39.002z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share ChatGPT has taken the world by storm. What's Next? on reddit" href="https://reddit.com/submit?url=https%3a%2f%2flifei.ai%2fposts%2f2023-04-06-chatgpt%2f&title=ChatGPT%20has%20taken%20the%20world%20by%20storm.%20What%27s%20Next%3f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM446 265.638c0-22.964-18.616-41.58-41.58-41.58-11.211.0-21.361 4.457-28.841 11.666-28.424-20.508-67.586-33.757-111.204-35.278l18.941-89.121 61.884 13.157c.756 15.734 13.642 28.29 29.56 28.29 16.407.0 29.706-13.299 29.706-29.701.0-16.403-13.299-29.702-29.706-29.702-11.666.0-21.657 6.792-26.515 16.578l-69.105-14.69c-1.922-.418-3.939-.042-5.585 1.036-1.658 1.073-2.811 2.761-3.224 4.686l-21.152 99.438c-44.258 1.228-84.046 14.494-112.837 35.232-7.468-7.164-17.589-11.591-28.757-11.591-22.965.0-41.585 18.616-41.585 41.58.0 16.896 10.095 31.41 24.568 37.918-.639 4.135-.99 8.328-.99 12.576.0 63.977 74.469 115.836 166.33 115.836s166.334-51.859 166.334-115.836c0-4.218-.347-8.387-.977-12.493 14.564-6.47 24.735-21.034 24.735-38.001zM326.526 373.831c-20.27 20.241-59.115 21.816-70.534 21.816-11.428.0-50.277-1.575-70.522-21.82-3.007-3.008-3.007-7.882.0-10.889 3.003-2.999 7.882-3.003 10.885.0 12.777 12.781 40.11 17.317 59.637 17.317 19.522.0 46.86-4.536 59.657-17.321 3.016-2.999 7.886-2.995 10.885.008 3.008 3.011 3.003 7.882-.008 10.889zm-5.23-48.781c-16.373.0-29.701-13.324-29.701-29.698.0-16.381 13.328-29.714 29.701-29.714 16.378.0 29.706 13.333 29.706 29.714.0 16.374-13.328 29.698-29.706 29.698zM160.91 295.348c0-16.381 13.328-29.71 29.714-29.71 16.369.0 29.689 13.329 29.689 29.71.0 16.373-13.32 29.693-29.689 29.693-16.386.0-29.714-13.32-29.714-29.693z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share ChatGPT has taken the world by storm. What's Next? on facebook" href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2flifei.ai%2fposts%2f2023-04-06-chatgpt%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H342.978V319.085h66.6l12.672-82.621h-79.272v-53.617c0-22.603 11.073-44.636 46.58-44.636H425.6v-70.34s-32.71-5.582-63.982-5.582c-65.288.0-107.96 39.569-107.96 111.204v62.971h-72.573v82.621h72.573V512h-191.104c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share ChatGPT has taken the world by storm. What's Next? on whatsapp" href="https://api.whatsapp.com/send?text=ChatGPT%20has%20taken%20the%20world%20by%20storm.%20What%27s%20Next%3f%20-%20https%3a%2f%2flifei.ai%2fposts%2f2023-04-06-chatgpt%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zm-58.673 127.703c-33.842-33.881-78.847-52.548-126.798-52.568-98.799.0-179.21 80.405-179.249 179.234-.013 31.593 8.241 62.428 23.927 89.612l-25.429 92.884 95.021-24.925c26.181 14.28 55.659 21.807 85.658 21.816h.074c98.789.0 179.206-80.413 179.247-179.243.018-47.895-18.61-92.93-52.451-126.81zM263.976 403.485h-.06c-26.734-.01-52.954-7.193-75.828-20.767l-5.441-3.229-56.386 14.792 15.05-54.977-3.542-5.637c-14.913-23.72-22.791-51.136-22.779-79.287.033-82.142 66.867-148.971 149.046-148.971 39.793.014 77.199 15.531 105.329 43.692 28.128 28.16 43.609 65.592 43.594 105.4-.034 82.149-66.866 148.983-148.983 148.984zm81.721-111.581c-4.479-2.242-26.499-13.075-30.604-14.571-4.105-1.495-7.091-2.241-10.077 2.241-2.986 4.483-11.569 14.572-14.182 17.562-2.612 2.988-5.225 3.364-9.703 1.12-4.479-2.241-18.91-6.97-36.017-22.23C231.8 264.15 222.81 249.484 220.198 245s-.279-6.908 1.963-9.14c2.016-2.007 4.48-5.232 6.719-7.847 2.24-2.615 2.986-4.484 4.479-7.472 1.493-2.99.747-5.604-.374-7.846-1.119-2.241-10.077-24.288-13.809-33.256-3.635-8.733-7.327-7.55-10.077-7.688-2.609-.13-5.598-.158-8.583-.158-2.986.0-7.839 1.121-11.944 5.604-4.105 4.484-15.675 15.32-15.675 37.364.0 22.046 16.048 43.342 18.287 46.332 2.24 2.99 31.582 48.227 76.511 67.627 10.685 4.615 19.028 7.371 25.533 9.434 10.728 3.41 20.492 2.929 28.209 1.775 8.605-1.285 26.499-10.833 30.231-21.295 3.732-10.464 3.732-19.431 2.612-21.298-1.119-1.869-4.105-2.99-8.583-5.232z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share ChatGPT has taken the world by storm. What's Next? on telegram" href="https://telegram.me/share/url?text=ChatGPT%20has%20taken%20the%20world%20by%20storm.%20What%27s%20Next%3f&amp;url=https%3a%2f%2flifei.ai%2fposts%2f2023-04-06-chatgpt%2f"><svg viewBox="2 2 28 28" height="30" width="30" fill="currentcolor"><path d="M26.49 29.86H5.5a3.37 3.37.0 01-2.47-1 3.35 3.35.0 01-1-2.47V5.48A3.36 3.36.0 013 3 3.37 3.37.0 015.5 2h21A3.38 3.38.0 0129 3a3.36 3.36.0 011 2.46V26.37a3.35 3.35.0 01-1 2.47 3.38 3.38.0 01-2.51 1.02zm-5.38-6.71a.79.79.0 00.85-.66L24.73 9.24a.55.55.0 00-.18-.46.62.62.0 00-.41-.17q-.08.0-16.53 6.11a.59.59.0 00-.41.59.57.57.0 00.43.52l4 1.24 1.61 4.83a.62.62.0 00.63.43.56.56.0 00.4-.17L16.54 20l4.09 3A.9.9.0 0021.11 23.15zM13.8 20.71l-1.21-4q8.72-5.55 8.78-5.55c.15.0.23.0.23.16a.18.18.0 010 .06s-2.51 2.3-7.52 6.8z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share ChatGPT has taken the world by storm. What's Next? on ycombinator" href="https://news.ycombinator.com/submitlink?t=ChatGPT%20has%20taken%20the%20world%20by%20storm.%20What%27s%20Next%3f&u=https%3a%2f%2flifei.ai%2fposts%2f2023-04-06-chatgpt%2f"><svg width="30" height="30" viewBox="0 0 512 512" fill="currentcolor" xmlns:inkscape="http://www.inkscape.org/namespaces/inkscape"><path d="M449.446.0C483.971.0 512 28.03 512 62.554V449.446C512 483.97 483.97 512 449.446 512H62.554C28.03 512 0 483.97.0 449.446V62.554C0 28.03 28.029.0 62.554.0H449.446zM183.8767 87.9921h-62.034L230.6673 292.4508V424.0079h50.6655V292.4508L390.1575 87.9921H328.1233L256 238.2489z"/></svg></a></li></ul></footer></article></main><footer class=footer><span>&copy; 2025 <a href=https://lifei.ai/>Fei Li</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg></a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"auto"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="copy";function s(){t.innerHTML="copied!",setTimeout(()=>{t.innerHTML="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>